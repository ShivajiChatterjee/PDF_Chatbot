{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjuqLe6K-i0c",
        "outputId": "0ede69c8-da5d-453a-8f9c-1f8ad00532b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting llama-index==0.5.6\n",
            "  Downloading llama_index-0.5.6.tar.gz (165 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/165.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting dataclasses_json (from llama-index==0.5.6)\n",
            "  Downloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
            "Collecting langchain (from llama-index==0.5.6)\n",
            "  Downloading langchain-0.0.338-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index==0.5.6) (1.23.5)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index==0.5.6) (8.2.3)\n",
            "Collecting openai>=0.26.4 (from llama-index==0.5.6)\n",
            "  Downloading openai-1.3.3-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.3/220.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index==0.5.6) (1.5.3)\n",
            "Collecting tiktoken (from llama-index==0.5.6)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index==0.5.6) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=0.26.4->llama-index==0.5.6) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=0.26.4->llama-index==0.5.6)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index==0.5.6) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index==0.5.6) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai>=0.26.4->llama-index==0.5.6) (4.5.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses_json->llama-index==0.5.6)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses_json->llama-index==0.5.6)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->llama-index==0.5.6) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->llama-index==0.5.6) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->llama-index==0.5.6) (3.8.6)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->llama-index==0.5.6) (4.0.3)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain->llama-index==0.5.6)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain->llama-index==0.5.6)\n",
            "  Downloading langsmith-0.0.65-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain->llama-index==0.5.6) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index==0.5.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index==0.5.6) (2023.3.post1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->llama-index==0.5.6) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama-index==0.5.6) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama-index==0.5.6) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama-index==0.5.6) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama-index==0.5.6) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama-index==0.5.6) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->llama-index==0.5.6) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai>=0.26.4->llama-index==0.5.6) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai>=0.26.4->llama-index==0.5.6) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai>=0.26.4->llama-index==0.5.6) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=0.26.4->llama-index==0.5.6) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai>=0.26.4->llama-index==0.5.6)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain->llama-index==0.5.6)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses_json->llama-index==0.5.6) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index==0.5.6) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->llama-index==0.5.6) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->llama-index==0.5.6) (3.0.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses_json->llama-index==0.5.6)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai>=0.26.4->llama-index==0.5.6)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-index\n",
            "  Building wheel for llama-index (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-index: filename=llama_index-0.5.6-py3-none-any.whl size=248133 sha256=f60a6d946e1cba60f1eeb5d2490692fd85585d1e29bc7bdad9f36fc33fd18cd7\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/9f/0a/a5d7181a1819086f8288d1becdad81de07fc874b55075dde19\n",
            "Successfully built llama-index\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, tiktoken, langsmith, jsonpatch, httpcore, httpx, dataclasses_json, openai, langchain, llama-index\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses_json-0.6.2 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.338 langsmith-0.0.65 llama-index-0.5.6 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.3 tiktoken-0.5.1 typing-inspect-0.9.0\n",
            "Collecting langchain==0.0.148\n",
            "  Downloading langchain-0.0.148-py3-none-any.whl (636 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.7/636.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (6.0.1)\n",
            "Collecting SQLAlchemy<2,>=1 (from langchain==0.0.148)\n",
            "  Downloading SQLAlchemy-1.4.50-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (3.8.6)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.148)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (2.8.7)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (1.23.5)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.148)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (8.2.3)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.148) (4.66.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.148) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.148) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.148) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.148) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.148) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.148) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.148) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain==0.0.148) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.148) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.148) (1.0.0)\n",
            "Installing collected packages: SQLAlchemy, openapi-schema-pydantic, dataclasses-json, langchain\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.23\n",
            "    Uninstalling SQLAlchemy-2.0.23:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.23\n",
            "  Attempting uninstall: dataclasses-json\n",
            "    Found existing installation: dataclasses-json 0.6.2\n",
            "    Uninstalling dataclasses-json-0.6.2:\n",
            "      Successfully uninstalled dataclasses-json-0.6.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.0.338\n",
            "    Uninstalling langchain-0.0.338:\n",
            "      Successfully uninstalled langchain-0.0.338\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.50 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SQLAlchemy-1.4.50 dataclasses-json-0.5.14 langchain-0.0.148 openapi-schema-pydantic-1.2.4\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.3.3\n",
            "    Uninstalling openai-1.3.3:\n",
            "      Successfully uninstalled openai-1.3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index==0.5.6\n",
        "!pip install langchain==0.0.148\n",
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4-80m6x-ywc",
        "outputId": "16b4d6d7-c8d7-4af2-85dd-28e398f426f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pink in italian?\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to have a good idea of what you're looking for.\n",
            "\n",
            "I think it's a good idea to\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import openai\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Set your Hugging Face token as an environment variable.\n",
        "os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = \"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\"\n",
        "\n",
        "class Chatbot:\n",
        "    def __init__(self, model_path, dataset_path):\n",
        "        # Load the pre-trained GPT-2 model.\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(model_path, token=\"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\")\n",
        "\n",
        "        # Load the tokenizer.\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "        # Load the dataset.\n",
        "        with open(dataset_path, \"r\") as f:\n",
        "            self.dataset = json.load(f)\n",
        "\n",
        "        # Initialize the conversation history.\n",
        "        self.conversation_history = []\n",
        "\n",
        "    def generate_response(self, query):\n",
        "        # Add the user query to the conversation history.\n",
        "        self.conversation_history.append(query)\n",
        "\n",
        "        # Encode the query.\n",
        "        input_ids = self.tokenizer.encode(query, return_tensors=\"pt\")\n",
        "\n",
        "        # Set the attention mask.\n",
        "        attention_mask = torch.ones_like(input_ids)\n",
        "\n",
        "        # Set the pad token id.\n",
        "        pad_token_id = self.tokenizer.eos_token_id\n",
        "\n",
        "        # Generate a response using the model.\n",
        "        response = self.model.generate(\n",
        "            max_length=1024, input_ids=input_ids, attention_mask=attention_mask, pad_token_id=pad_token_id\n",
        "        )\n",
        "\n",
        "        # Decode the generated response tensor to obtain the text.\n",
        "        response_text = self.tokenizer.decode(response[0], skip_special_tokens=True)\n",
        "\n",
        "        return response_text\n",
        "\n",
        "# Create a chatbot instance.\n",
        "chatbot = Chatbot(\"gpt2\", \"dataset.json\")\n",
        "\n",
        "# Start a conversation with the chatbot.\n",
        "while True:\n",
        "    query = input(\"What would you like to know? \")\n",
        "    response = chatbot.generate_response(query)\n",
        "    print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKJFlUyP_Fyw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}